[
  {
    "title": "Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation",
    "url": "http://arxiv.org/abs/2508.05635v1",
    "published_date": "2025-08-07T17:59:44+00:00",
    "source_platform": "arXiv",
    "content": "We introduce Genie Envisioner (GE), a unified world foundation platform for\nrobotic manipulation that integrates policy learning, evaluation, and\nsimulation within a single video-generative framework. At its core, GE-Base is\na large-scale, instruction-conditioned video diffusion model that captures the\nspatial, temporal, and semantic dynamics of real-world robotic interactions in\na structured latent space. Built upon this foundation, GE-Act maps latent\nrepresentations to executable action trajectories through a lightweight,\nflow-matching decoder, enabling precise and generalizable policy inference\nacross diverse embodiments with minimal supervision. To support scalable\nevaluation and training, GE-Sim serves as an action-conditioned neural\nsimulator, producing high-fidelity rollouts for closed-loop policy development.\nThe platform is further equipped with EWMBench, a standardized benchmark suite\nmeasuring visual fidelity, physical consistency, and instruction-action\nalignment. Together, these components establish Genie Envisioner as a scalable\nand practical foundation for instruction-driven, general-purpose embodied\nintelligence. All code, models, and benchmarks will be released publicly."
  },
  {
    "title": "Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling",
    "url": "http://arxiv.org/abs/2508.05634v1",
    "published_date": "2025-08-07T17:59:43+00:00",
    "source_platform": "arXiv",
    "content": "Mobile robots navigating in crowds trained using reinforcement learning are\nknown to suffer performance degradation when faced with out-of-distribution\nscenarios. We propose that by properly accounting for the uncertainties of\npedestrians, a robot can learn safe navigation policies that are robust to\ndistribution shifts. Our method augments agent observations with prediction\nuncertainty estimates generated by adaptive conformal inference, and it uses\nthese estimates to guide the agent's behavior through constrained reinforcement\nlearning. The system helps regulate the agent's actions and enables it to adapt\nto distribution shifts. In the in-distribution setting, our approach achieves a\n96.93% success rate, which is over 8.80% higher than the previous\nstate-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times\nfewer intrusions into ground-truth human future trajectories. In three\nout-of-distribution scenarios, our method shows much stronger robustness when\nfacing distribution shifts in velocity variations, policy changes, and\ntransitions from individual to group dynamics. We deploy our method on a real\nrobot, and experiments show that the robot makes safe and robust decisions when\ninteracting with both sparse and dense crowds. Our code and videos are\navailable on https://gen-safe-nav.github.io/."
  },
  {
    "title": "KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation",
    "url": "http://arxiv.org/abs/2508.05633v1",
    "published_date": "2025-08-07T17:59:36+00:00",
    "source_platform": "arXiv",
    "content": "Live streaming platforms have become a dominant form of online content\nconsumption, offering dynamically evolving content, real-time interactions, and\nhighly engaging user experiences. These unique characteristics introduce new\nchallenges that differentiate live streaming recommendation from traditional\nrecommendation settings and have garnered increasing attention from industry in\nrecent years. However, research progress in academia has been hindered by the\nlack of publicly available datasets that accurately reflect the dynamic nature\nof live streaming environments. To address this gap, we introduce KuaiLive, the\nfirst real-time, interactive dataset collected from Kuaishou, a leading live\nstreaming platform in China with over 400 million daily active users. The\ndataset records the interaction logs of 23,772 users and 452,621 streamers over\na 21-day period. Compared to existing datasets, KuaiLive offers several\nadvantages: it includes precise live room start and end timestamps, multiple\ntypes of real-time user interactions (click, comment, like, gift), and rich\nside information features for both users and streamers. These features enable\nmore realistic simulation of dynamic candidate items and better modeling of\nuser and streamer behaviors. We conduct a thorough analysis of KuaiLive from\nmultiple perspectives and evaluate several representative recommendation\nmethods on it, establishing a strong benchmark for future research. KuaiLive\ncan support a wide range of tasks in the live streaming domain, such as top-K\nrecommendation, click-through rate prediction, watch time prediction, and gift\nprice prediction. Moreover, its fine-grained behavioral data also enables\nresearch on multi-behavior modeling, multi-task learning, and fairness-aware\nrecommendation. The dataset and related resources are publicly available at\nhttps://imgkkk574.github.io/KuaiLive."
  },
  {
    "title": "H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages",
    "url": "http://arxiv.org/abs/2508.05628v1",
    "published_date": "2025-08-07T17:59:01+00:00",
    "source_platform": "arXiv",
    "content": "Byte-level language models eliminate fragile tokenizers but face\ncomputational challenges in morphologically-rich languages (MRLs), where words\nspan many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that\nlearns linguistically-informed segmentation through end-to-end training. Key\ninnovations include: (1) a lightweight Transformer context-mixer (1.9M\nparameters) for cross-chunk attention, (2) a two-level latent hyper-prior for\ndocument-level consistency, (3) specialized handling of orthographic artifacts\n(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence\nlengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art\nresults: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better\ncompression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ\ncorruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks\nalign with Persian morphology without explicit supervision, demonstrating that\nhierarchical dynamic chunking provides an effective tokenizer-free solution for\nMRLs while maintaining computational efficiency."
  },
  {
    "title": "How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations",
    "url": "http://arxiv.org/abs/2508.05625v1",
    "published_date": "2025-08-07T17:58:41+00:00",
    "source_platform": "arXiv",
    "content": "Large Language Models (LLMs) have started to demonstrate the ability to\npersuade humans, yet our understanding of how this dynamic transpires is\nlimited. Recent work has used linear probes, lightweight tools for analyzing\nmodel representations, to study various LLM skills such as the ability to model\nuser sentiment and political perspective. Motivated by this, we apply probes to\nstudy persuasion dynamics in natural, multi-turn conversations. We leverage\ninsights from cognitive science to train probes on distinct aspects of\npersuasion: persuasion success, persuadee personality, and persuasion strategy.\nDespite their simplicity, we show that they capture various aspects of\npersuasion at both the sample and dataset levels. For instance, probes can\nidentify the point in a conversation where the persuadee was persuaded or where\npersuasive success generally occurs across the entire dataset. We also show\nthat in addition to being faster than expensive prompting-based approaches,\nprobes can do just as well and even outperform prompting in some settings, such\nas when uncovering persuasion strategy. This suggests probes as a plausible\navenue for studying other complex behaviours such as deception and\nmanipulation, especially in multi-turn settings and large-scale dataset\nanalysis where prompting-based methods would be computationally inefficient."
  },
  {
    "title": "Simulating Human-Like Learning Dynamics with LLM-Empowered Agents",
    "url": "http://arxiv.org/abs/2508.05622v1",
    "published_date": "2025-08-07T17:57:46+00:00",
    "source_platform": "arXiv",
    "content": "Capturing human learning behavior based on deep learning methods has become a\nmajor research focus in both psychology and intelligent systems. Recent\napproaches rely on controlled experiments or rule-based models to explore\ncognitive processes. However, they struggle to capture learning dynamics, track\nprogress over time, or provide explainability. To address these challenges, we\nintroduce LearnerAgent, a novel multi-agent framework based on Large Language\nModels (LLMs) to simulate a realistic teaching environment. To explore\nhuman-like learning dynamics, we construct learners with psychologically\ngrounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free\nGeneral Learner to inspect the base LLM's default behavior. Through weekly\nknowledge acquisition, monthly strategic choices, periodic tests, and peer\ninteraction, we can track the dynamic learning progress of individual learners\nover a full-year journey. Our findings are fourfold: 1) Longitudinal analysis\nreveals that only Deep Learner achieves sustained cognitive growth. Our\nspecially designed \"trap questions\" effectively diagnose Surface Learner's\nshallow knowledge. 2) The behavioral and cognitive patterns of distinct\nlearners align closely with their psychological profiles. 3) Learners'\nself-concept scores evolve realistically, with the General Learner developing\nsurprisingly high self-efficacy despite its cognitive limitations. 4)\nCritically, the default profile of base LLM is a \"diligent but brittle Surface\nLearner\"-an agent that mimics the behaviors of a good student but lacks true,\ngeneralizable understanding. Extensive simulation experiments demonstrate that\nLearnerAgent aligns well with real scenarios, yielding more insightful findings\nabout LLMs' behavior."
  },
  {
    "title": "The Missing Reward: Active Inference in the Era of Experience",
    "url": "http://arxiv.org/abs/2508.05619v1",
    "published_date": "2025-08-07T17:57:12+00:00",
    "source_platform": "arXiv",
    "content": "This paper argues that Active Inference (AIF) provides a crucial foundation\nfor developing autonomous AI agents capable of learning from experience without\ncontinuous human reward engineering. As AI systems begin to exhaust\nhigh-quality training data and rely on increasingly large human workforces for\nreward design, the current paradigm faces significant scalability challenges\nthat could impede progress toward genuinely autonomous intelligence. The\nproposal for an ``Era of Experience,'' where agents learn from self-generated\ndata, is a promising step forward. However, this vision still depends on\nextensive human engineering of reward functions, effectively shifting the\nbottleneck from data curation to reward curation. This highlights what we\nidentify as the \\textbf{grounded-agency gap}: the inability of contemporary AI\nsystems to autonomously formulate, adapt, and pursue objectives in response to\nchanging circumstances. We propose that AIF can bridge this gap by replacing\nexternal reward signals with an intrinsic drive to minimize free energy,\nallowing agents to naturally balance exploration and exploitation through a\nunified Bayesian objective. By integrating Large Language Models as generative\nworld models with AIF's principled decision-making framework, we can create\nagents that learn efficiently from experience while remaining aligned with\nhuman values. This synthesis offers a compelling path toward AI systems that\ncan develop autonomously while adhering to both computational and physical\nconstraints."
  },
  {
    "title": "TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution",
    "url": "http://arxiv.org/abs/2508.05616v1",
    "published_date": "2025-08-07T17:55:10+00:00",
    "source_platform": "arXiv",
    "content": "Trajectory prediction is a critical task in modeling human behavior,\nespecially in safety-critical domains such as social robotics and autonomous\nvehicle navigation. Traditional heuristics based on handcrafted rules often\nlack accuracy and generalizability. Although deep learning approaches offer\nimproved performance, they typically suffer from high computational cost,\nlimited explainability, and, importantly, poor generalization to\nout-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a\nframework that leverages Large Language Models (LLMs) to automatically design\ntrajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to\ngenerate and refine prediction heuristics from past trajectory data. We propose\ntwo key innovations: Cross-Generation Elite Sampling to encourage population\ndiversity, and a Statistics Feedback Loop that enables the LLM to analyze and\nimprove alternative predictions. Our evaluations demonstrate that TrajEvo\noutperforms existing heuristic methods across multiple real-world datasets, and\nnotably surpasses both heuristic and deep learning methods in generalizing to\nan unseen OOD real-world dataset. TrajEvo marks a promising step toward the\nautomated design of fast, explainable, and generalizable trajectory prediction\nheuristics. We release our source code to facilitate future research at\nhttps://github.com/ai4co/trajevo."
  },
  {
    "title": "Test-Time Reinforcement Learning for GUI Grounding via Region Consistency",
    "url": "http://arxiv.org/abs/2508.05615v1",
    "published_date": "2025-08-07T17:54:27+00:00",
    "source_platform": "arXiv",
    "content": "Graphical User Interface (GUI) grounding, the task of mapping natural\nlanguage instructions to precise screen coordinates, is fundamental to\nautonomous GUI agents. While existing methods achieve strong performance\nthrough extensive supervised training or reinforcement learning with labeled\nrewards, they remain constrained by the cost and availability of pixel-level\nannotations. We observe that when models generate multiple predictions for the\nsame GUI element, the spatial overlap patterns reveal implicit confidence\nsignals that can guide more accurate localization. Leveraging this insight, we\npropose GUI-RC (Region Consistency), a test-time scaling method that constructs\nspatial voting grids from multiple sampled predictions to identify consensus\nregions where models show highest agreement. Without any training, GUI-RC\nimproves accuracy by 2-3% across various architectures on ScreenSpot\nbenchmarks. We further introduce GUI-RCPO (Region Consistency Policy\nOptimization), which transforms these consistency patterns into rewards for\ntest-time reinforcement learning. By computing how well each prediction aligns\nwith the collective consensus, GUI-RCPO enables models to iteratively refine\ntheir outputs on unlabeled data during inference. Extensive experiments\ndemonstrate the generality of our approach: GUI-RC boosts\nQwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO\nfurther improves it to 85.14% through self-supervised optimization. Our\napproach reveals the untapped potential of test-time scaling and test-time\nreinforcement learning for GUI grounding, offering a promising path toward more\nrobust and data-efficient GUI agents."
  },
  {
    "title": "OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks",
    "url": "http://arxiv.org/abs/2508.05614v1",
    "published_date": "2025-08-07T17:54:15+00:00",
    "source_platform": "arXiv",
    "content": "Large language models excel at abstract reasoning but their capacity for\nembodied agent reasoning remains largely unexplored. We present OmniEAR, a\ncomprehensive framework for evaluating how language models reason about\nphysical interactions, tool usage, and multi-agent coordination in embodied\ntasks. Unlike existing benchmarks that provide predefined tool sets or explicit\ncollaboration directives, OmniEAR requires agents to dynamically acquire\ncapabilities and autonomously determine coordination strategies based on task\ndemands. Through text-based environment representation, we model continuous\nphysical properties and complex spatial relationships across 1,500 scenarios\nspanning household and industrial domains. Our systematic evaluation reveals\nsevere performance degradation when models must reason from constraints: while\nachieving 85-96% success with explicit instructions, performance drops to\n56-85% for tool reasoning and 63-85% for implicit collaboration, with compound\ntasks showing over 50% failure rates. Surprisingly, complete environmental\ninformation degrades coordination performance, indicating models cannot filter\ntask-relevant constraints. Fine-tuning improves single-agent tasks dramatically\n(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing\nfundamental architectural limitations. These findings demonstrate that embodied\nreasoning poses fundamentally different challenges than current models can\naddress, establishing OmniEAR as a rigorous benchmark for evaluating and\nadvancing embodied AI systems. Our code and data are included in the\nsupplementary materials and will be open-sourced upon acceptance."
  },
  {
    "title": "polarsource /\n\n      polar",
    "url": "https://github.com/polarsource/polar",
    "content": "Language: Python. An open source engine for your digital products. Sell SaaS and digital products in minutes.",
    "published_date": "2025-08-10T20:41:49.433630+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "hesreallyhim /\n\n      awesome-claude-code",
    "url": "https://github.com/hesreallyhim/awesome-claude-code",
    "content": "Language: Python. A curated list of awesome commands, files, and workflows for Claude Code",
    "published_date": "2025-08-10T20:41:49.433700+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "lfnovo /\n\n      open-notebook",
    "url": "https://github.com/lfnovo/open-notebook",
    "content": "Language: Python. An Open Source implementation of Notebook LM with more flexibility and features",
    "published_date": "2025-08-10T20:41:49.433780+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "sinaptik-ai /\n\n      pandas-ai",
    "url": "https://github.com/sinaptik-ai/pandas-ai",
    "content": "Language: Python. Chat with your database or your datalake (SQL, CSV, parquet). PandasAI makes data analysis conversational using LLMs and RAG.",
    "published_date": "2025-08-10T20:41:49.433831+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "DevilXD /\n\n      TwitchDropsMiner",
    "url": "https://github.com/DevilXD/TwitchDropsMiner",
    "content": "Language: Python. An app that allows you to AFK mine timed Twitch drops, with automatic drop claiming and channel switching.",
    "published_date": "2025-08-10T20:41:49.433899+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "tadata-org /\n\n      fastapi_mcp",
    "url": "https://github.com/tadata-org/fastapi_mcp",
    "content": "Language: Python. Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
    "published_date": "2025-08-10T20:41:49.433950+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "ucbepic /\n\n      docetl",
    "url": "https://github.com/ucbepic/docetl",
    "content": "Language: Python. A system for agentic LLM-powered data processing and ETL",
    "published_date": "2025-08-10T20:41:49.434001+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "omkarcloud /\n\n      botasaurus",
    "url": "https://github.com/omkarcloud/botasaurus",
    "content": "Language: Python. The All in One Framework to Build Undefeatable Scrapers",
    "published_date": "2025-08-10T20:41:49.434068+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "yt-dlp /\n\n      yt-dlp",
    "url": "https://github.com/yt-dlp/yt-dlp",
    "content": "Language: Python. A feature-rich command-line audio/video downloader",
    "published_date": "2025-08-10T20:41:49.434119+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "openai /\n\n      openai-python",
    "url": "https://github.com/openai/openai-python",
    "content": "Language: Python. The official Python library for the OpenAI API",
    "published_date": "2025-08-10T20:41:49.434169+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "PacktPublishing /\n\n      LLM-Engineers-Handbook",
    "url": "https://github.com/PacktPublishing/LLM-Engineers-Handbook",
    "content": "Language: Python. The LLM's practical guide: From the fundamentals to deploying advanced LLM and RAG apps to AWS using LLMOps best practices",
    "published_date": "2025-08-10T20:41:49.434220+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "commaai /\n\n      openpilot",
    "url": "https://github.com/commaai/openpilot",
    "content": "Language: Python. openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.",
    "published_date": "2025-08-10T20:41:49.434270+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "nottelabs /\n\n      notte",
    "url": "https://github.com/nottelabs/notte",
    "content": "Language: Python. üî• Reliable Browser AI agents (YC S25)",
    "published_date": "2025-08-10T20:41:49.434321+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "funstory-ai /\n\n      BabelDOC",
    "url": "https://github.com/funstory-ai/BabelDOC",
    "content": "Language: Python. Yet Another Document Translator",
    "published_date": "2025-08-10T20:41:49.434371+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "modelscope /\n\n      DiffSynth-Studio",
    "url": "https://github.com/modelscope/DiffSynth-Studio",
    "content": "Language: Python. Enjoy the magic of Diffusion models!",
    "published_date": "2025-08-10T20:41:49.434422+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "exo-explore /\n\n      exo",
    "url": "https://github.com/exo-explore/exo",
    "content": "Language: Python. Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö",
    "published_date": "2025-08-10T20:41:49.434473+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "unslothai /\n\n      unsloth",
    "url": "https://github.com/unslothai/unsloth",
    "content": "Language: Python. Fine-tuning & Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70% less VRAM.",
    "published_date": "2025-08-10T20:41:49.434539+00:00",
    "source_platform": "GitHub Trending (python)"
  },
  {
    "title": "The Download: GPT-5 is here, and Intel‚Äôs CEO drama",
    "url": "https://www.technologyreview.com/2025/08/08/1121330/the-download-gpt-5-is-here-and-intels-ceo-drama/",
    "content": "This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. GPT-5 is here. Now what? At long last, OpenAI has released GPT-5. The new system abandons the distinction between OpenAI‚Äôs flagship models and its o series of reasoning models, automatically routing user queries&#8230;",
    "published_date": "2025-08-08T06:40:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "GPT-5 is here. Now what?",
    "url": "https://www.technologyreview.com/2025/08/07/1121308/gpt-5-is-here-now-what/",
    "content": "At long last, OpenAI has released GPT-5. The new system abandons the distinction between OpenAI‚Äôs flagship models and its o series of reasoning models, automatically routing user queries to a fast nonreasoning model or a slower reasoning version. It is now available to everyone through the ChatGPT web interface‚Äîthough nonpaying users may need to wait&#8230;",
    "published_date": "2025-08-07T11:30:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "The Download: how AI is improving itself, and hidden greenhouse gases",
    "url": "https://www.technologyreview.com/2025/08/07/1121303/the-download-how-ai-is-improving-itself-and-hidden-greenhouse-gases/",
    "content": "This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Five ways that AI is learning to improve itself Last week, Mark Zuckerberg declared that Meta aims to achieve smarter-than-human AI. He seems to have a recipe for achieving that goal, and the&#8230;",
    "published_date": "2025-08-07T06:40:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "The greenhouse gases we‚Äôre not accounting for",
    "url": "https://www.technologyreview.com/2025/08/07/1121188/the-greenhouse-gases-were-not-accounting-for/",
    "content": "In the spring of 2021, climate scientists were stumped.&#160; The global economy was just emerging from the covid-19 lockdowns, but for some reason the levels of methane‚Äîa greenhouse gas emitted mainly through agriculture and fossil-fuel production‚Äîhad soared in the atmosphere the previous year, rising at the fastest rate on record. Researchers around the world set&#8230;",
    "published_date": "2025-08-07T03:30:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "Five ways that AI is learning to improve itself",
    "url": "https://www.technologyreview.com/2025/08/06/1121193/five-ways-that-ai-is-learning-to-improve-itself/",
    "content": "Last week, Mark Zuckerberg declared that Meta is aiming to achieve smarter-than-human AI. He seems to have a recipe for achieving that goal, and the first ingredient is human talent: Zuckerberg has reportedly tried to lure top researchers to Meta Superintelligence Labs with nine-figure offers. The second ingredient is AI itself.&#160; Zuckerberg recently said on&#8230;",
    "published_date": "2025-08-06T09:44:12+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "The Download: OpenAI‚Äôs open-weight models, and the future of internet search",
    "url": "https://www.technologyreview.com/2025/08/06/1121179/the-download-openais-open-weight-models-and-the-future-of-internet-search/",
    "content": "This is today&#8217;s edition of¬†The Download,¬†our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. OpenAI has finally released open-weight language models The news: OpenAI has finally released its first open-weight large language models since 2019‚Äôs GPT-2. Unlike the models available through OpenAI‚Äôs web interface, these new open&#8230;",
    "published_date": "2025-08-06T06:40:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "OpenAI has finally released open-weight language models",
    "url": "https://www.technologyreview.com/2025/08/05/1121092/openai-has-finally-released-open-weight-language-models/",
    "content": "OpenAI has finally released its first open-weight large language models since 2019‚Äôs GPT-2. These new ‚Äúgpt-oss‚Äù models are available in two different sizes and score similarly to the company‚Äôs o3-mini and o4-mini models on several benchmarks. Unlike the models available through OpenAI‚Äôs web interface, these new open models can be freely downloaded, run, and even&#8230;",
    "published_date": "2025-08-05T11:30:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "The Download: AI agent infrastructure, and OpenAI‚Äôs ambitions",
    "url": "https://www.technologyreview.com/2025/08/05/1121056/the-download-ai-agent-infrastructure-openai-ambitions/",
    "content": "This is today&#8217;s edition of&#160;The Download,&#160;our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. These protocols will help AI agents navigate our messy lives A growing number of companies are launching AI agents that can do things on your behalf‚Äîactions like sending an email, making a document,&#8230;",
    "published_date": "2025-08-05T06:30:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "A glimpse into OpenAI‚Äôs largest ambitions",
    "url": "https://www.technologyreview.com/2025/08/05/1121052/a-glimpse-into-openais-largest-ambitions/",
    "content": "OpenAI has given itself a dual mandate. On the one hand, it‚Äôs a tech giant rooted in products, including of course ChatGPT, which people around the world reportedly send 2.5 billion requests to each day. But its original mission is to serve as a research lab that will not only create ‚Äúartificial general intelligence‚Äù but&#8230;",
    "published_date": "2025-08-05T03:30:00+00:00",
    "source_platform": "RSS - MIT Technology Review"
  },
  {
    "title": "These protocols will help AI agents navigate our messy lives",
    "url": "https://www.technologyreview.com/2025/08/04/1120996/protocols-help-agents-navigate-lives-mcp-a2a/",
    "content": "A growing number of companies are launching AI agents that can do things on your behalf‚Äîactions like sending an email, making a document, or editing a database. Initial reviews for these agents have been mixed at best, though, because they struggle to interact with all the different components of our digital lives. Part of the&#8230;",
    "published_date": "2025-08-04T09:30:13+00:00",
    "source_platform": "RSS - MIT Technology Review"
  }
]